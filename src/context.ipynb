{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miniconda3/envs/VulRAG/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n",
      "Context: this.state = 0; | Similarity: 0.9714752435684204\n",
      "Context: if (this.state > 10) this.resetState(); | Similarity: 0.9319815635681152\n",
      "Context: console.log(this.state); | Similarity: 0.7940301895141602\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "import os \n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:6666\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:6666\"\n",
    "\n",
    "# 加载 CodeBERT 模型\n",
    "model_name = \"microsoft/graphcodebert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"/home/models\")\n",
    "model = AutoModel.from_pretrained(model_name, cache_dir=\"/home/models\")\n",
    "\n",
    "def get_code_embedding(code_snippet):\n",
    "    inputs = tokenizer(code_snippet, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    # 获取 [CLS] 的嵌入作为整个代码片段的表示\n",
    "    return outputs.last_hidden_state[:, 0, :].detach()\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(vec1, vec2):\n",
    "    return cosine_similarity(vec1.reshape(1, -1), vec2.reshape(1, -1))[0][0]\n",
    "\n",
    "# 示例：缺陷代码和上下文代码片段\n",
    "defect_code = \"this.state = state + 1;\"\n",
    "context_snippets = [\n",
    "    \"this.state = 0;\",\n",
    "    \"console.log(this.state);\",\n",
    "    \"if (this.state > 10) this.resetState();\"\n",
    "]\n",
    "\n",
    "# 生成缺陷代码的向量\n",
    "defect_vec = get_code_embedding(defect_code)\n",
    "## 打印一下维度\n",
    "print(defect_vec.shape)\n",
    "\n",
    "# 生成上下文代码的向量\n",
    "context_vectors = [get_code_embedding(snippet) for snippet in context_snippets]\n",
    "\n",
    "# 计算每个上下文片段的相似度\n",
    "similarities = [calculate_similarity(defect_vec, ctx_vec) for ctx_vec in context_vectors]\n",
    "\n",
    "# 根据相似度排序\n",
    "sorted_contexts = sorted(zip(context_snippets, similarities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 输出过滤和排序后的上下文\n",
    "for snippet, score in sorted_contexts:\n",
    "    print(f\"Context: {snippet} | Similarity: {score}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an AI debugging assistant. Your task is to fix the provided code based on the error log.\n",
    "\n",
    "### Input:\n",
    "Code snippets:\n",
    "{code_snippet}\n",
    "\n",
    "Error log:\n",
    "{error_log}\n",
    "\n",
    "### Task:\n",
    "Please analyze the code and error log, then provide the fixed code directly.\n",
    "Keep the original indentation of each code snippet.\n",
    "\n",
    "### Output format:\n",
    "Return the fixed code snippets with original indentation preserved.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_arkts_context(code: str, variable_name: str):\n",
    "    lines = code.split(\"\\n\")\n",
    "    context = {\n",
    "        \"definition\": [],\n",
    "        \"usage\": [], \n",
    "        \"blocks\": []\n",
    "    }\n",
    "    \n",
    "    # 匹配变量定义\n",
    "    definition_pattern = rf\"@State.*{variable_name}.*=.*;\"\n",
    "    # 匹配变量使用 \n",
    "    usage_pattern = rf\".*{variable_name}.*\"\n",
    "    # 匹配代码块上下文\n",
    "    block_pattern = rf\"(for|if|while).*{{\"\n",
    "\n",
    "    # 先找出所有blocks\n",
    "    for i, line in enumerate(lines):\n",
    "        if re.search(block_pattern, line):\n",
    "            block_end = i + 1\n",
    "            indent_level = len(line) - len(line.lstrip())  # 计算缩进层级\n",
    "            while block_end < len(lines) and (\n",
    "                len(lines[block_end].strip()) == 0 or  # 空行跳过\n",
    "                len(lines[block_end]) - len(lines[block_end].lstrip()) > indent_level  # 子块仍在范围内\n",
    "            ):\n",
    "                block_end += 1\n",
    "            context[\"blocks\"].append((i + 1, lines[i:block_end]))\n",
    "\n",
    "    # 移除嵌套子块\n",
    "    filtered_blocks = []\n",
    "    for start, block in context[\"blocks\"]:\n",
    "        if not any(start > parent_start and start < parent_end for parent_start, parent_block in filtered_blocks for parent_end in [parent_start + len(parent_block)]):\n",
    "            filtered_blocks.append((start, block))\n",
    "    context[\"blocks\"] = filtered_blocks\n",
    "\n",
    "    # 找出所有definition和usage\n",
    "    for i, line in enumerate(lines):\n",
    "        if re.search(definition_pattern, line):\n",
    "            # 检查是否在block中\n",
    "            in_block = False\n",
    "            for block_start, block in context[\"blocks\"]:\n",
    "                block_end = block_start + len(block)\n",
    "                if i + 1 >= block_start and i + 1 <= block_end:\n",
    "                    in_block = True\n",
    "                    break\n",
    "            if not in_block:\n",
    "                context[\"definition\"].append((i + 1, line))\n",
    "        elif re.search(usage_pattern, line):\n",
    "            # 检查是否在block中\n",
    "            in_block = False\n",
    "            for block_start, block in context[\"blocks\"]:\n",
    "                block_end = block_start + len(block)\n",
    "                if i + 1 >= block_start and i + 1 <= block_end:\n",
    "                    in_block = True\n",
    "                    break\n",
    "            if not in_block:\n",
    "                context[\"usage\"].append((i + 1, line))\n",
    "\n",
    "    return context\n",
    "\n",
    "# 示例代码\n",
    "arkts_code = \"\"\"\n",
    "import hilog from '@ohos.hilog'\n",
    "@Entry\n",
    "@Component\n",
    "struct MyComponent{\n",
    "  @State message: string = '';\n",
    "  build() {\n",
    "    Column() {\n",
    "      Button('点击打印日志')\n",
    "        .onClick(() => {\n",
    "          this.message = 'click';\n",
    "          for (let k = 0; k < 10; k++) {        \n",
    "            for(let j = 0; j < 10; j++) {\n",
    "              for (let i = 0; i < 10; i++) {\n",
    "                hilog.info(0x0000, 'TAG', '%{public}s', this.message);\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        })\n",
    "        .width('90%')\n",
    "        .backgroundColor(Color.Blue)\n",
    "        .fontColor(Color.White)\n",
    "        .margin({\n",
    "          top: 10\n",
    "        })\n",
    "    }\n",
    "    .justifyContent(FlexAlign.Start)\n",
    "    .alignItems(HorizontalAlign.Center)\n",
    "    .margin({\n",
    "      top: 15\n",
    "    })\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "variable_name = \"message\"\n",
    "context = extract_arkts_context(arkts_code, variable_name)\n",
    "\n",
    "# 合并所有代码片段并按行号排序\n",
    "code_snippets = []\n",
    "code_snippets.extend([(line_num, code) for line_num, code in context[\"definition\"]])\n",
    "code_snippets.extend([(line_num, code) for line_num, code in context[\"usage\"]])\n",
    "code_snippets.extend([(start, \"\\n\".join(block)) for start, block in context[\"blocks\"]])\n",
    "\n",
    "code_snippets.sort(key=lambda x: x[0])\n",
    "surrounding_context = [snippet for _, snippet in code_snippets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  @State message: string = '';\n",
      "          this.message = 'click';\n",
      "          for (let k = 0; k < 10; k++) {        \n",
      "            for(let j = 0; j < 10; j++) {\n",
      "              for (let i = 0; i < 10; i++) {\n",
      "                hilog.info(0x0000, 'TAG', '%{public}s', this.message);\n",
      "              }\n",
      "            }\n"
     ]
    }
   ],
   "source": [
    "### definition, usage, blocks都作为上下文, 不需要行号，直接拿代码块\n",
    "def flatten_str_or_list(item):\n",
    "    if isinstance(item, str):\n",
    "        return item\n",
    "    elif isinstance(item, list):\n",
    "        return \"\\n\".join(item)\n",
    "    return \"\"\n",
    "\n",
    "surrounding_context = \"\\n\".join(surrounding_context)\n",
    "\n",
    "print(surrounding_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "from llm import get_openai_answer\n",
    "\n",
    "## 提取潜在的```language内的内容\n",
    "def extract_code_from_response(response):\n",
    "    \"\"\"从回复中提取代码块内容\"\"\"\n",
    "    # 使用正则表达式匹配```开头和结尾的代码块\n",
    "    code_blocks = re.findall(r'```(?:\\w+)?\\n(.*?)```', response, re.DOTALL)\n",
    "    \n",
    "    # 如果找到多个代码块,拼接它们\n",
    "    if code_blocks:\n",
    "        return '\\n'.join(code_blocks)\n",
    "        \n",
    "    # 如果没找到代码块,返回原文\n",
    "    return response\n",
    "    \n",
    "\n",
    "error_log = \"Don't use state variable in the loop, use a local variable instead\"\n",
    "\n",
    "prompt = prompt_template.format(code_snippet=surrounding_context, error_log=error_log)\n",
    "\n",
    "response = get_openai_answer(prompt, model_name=\"gpt-4o-mini\")\n",
    "diff = extract_code_from_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  @State message: string = '';\n",
      "          const localMessage = 'click';\n",
      "          for (let k = 0; k < 10; k++) {        \n",
      "            for(let j = 0; j < 10; j++) {\n",
      "              for (let i = 0; i < 10; i++) {\n",
      "                hilog.info(0x0000, 'TAG', '%{public}s', localMessage);\n",
      "              }\n",
      "            }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'definition': [(6, \"  @State message: string = '';\")], 'usage': [(11, \"          this.message = 'click';\")], 'blocks': [(12, ['          for (let k = 0; k < 10; k++) {        ', '            for(let j = 0; j < 10; j++) {', '              for (let i = 0; i < 10; i++) {', \"                hilog.info(0x0000, 'TAG', '%{public}s', this.message);\", '              }', '            }'])]}\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修改后的代码:\n",
      "import hilog from '@ohos.hilog'\n",
      "@Entry\n",
      "@Component\n",
      "struct MyComponent{\n",
      "  @State message: string = '';\n",
      "  build() {\n",
      "    Column() {\n",
      "      Button('点击打印日志')\n",
      "        .onClick(() => {\n",
      "          const localMessage = 'click';\n",
      "          for (let k = 0; k < 10; k++) {        \n",
      "            for(let j = 0; j < 10; j++) {\n",
      "              for (let i = 0; i < 10; i++) {\n",
      "                hilog.info(0x0000, 'TAG', '%{public}s', localMessage);\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        })\n",
      "        .width('90%')\n",
      "        .backgroundColor(Color.Blue)\n",
      "        .fontColor(Color.White)\n",
      "        .margin({\n",
      "          top: 10\n",
      "        })\n",
      "    }\n",
      "    .justifyContent(FlexAlign.Start)\n",
      "    .alignItems(HorizontalAlign.Center)\n",
      "    .margin({\n",
      "      top: 15\n",
      "    })\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "### 通过context, surrounding context和diff，修改arkts_code\n",
    "def modify_arkts_code(original_code, context, surrounding_context, diff):\n",
    "    \"\"\"修改ArkTS代码\"\"\"\n",
    "    prompt = f\"\"\"请帮我修改以下ArkTS代码。\n",
    "\n",
    "原始代码:\n",
    "{original_code}\n",
    "\n",
    "提取出的有关上下文代码内容及行号：\n",
    "{context}\n",
    "\n",
    "对于上下文的修改代码:\n",
    "{diff}\n",
    "\n",
    "请返回完整的修改后代码，直接返回代码，不要返回任何其它内容。\n",
    "\"\"\"\n",
    "    # 获取修改建议\n",
    "    response = get_openai_answer(prompt)\n",
    "    \n",
    "    # 提取代码\n",
    "    modified_code = extract_code_from_response(response)\n",
    "    \n",
    "    return modified_code\n",
    "\n",
    "# 修改代码\n",
    "repair_code = modify_arkts_code(arkts_code, context, surrounding_context, diff)\n",
    "print(repair_code)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VulRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
